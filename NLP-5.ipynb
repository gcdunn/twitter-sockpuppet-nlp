{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "from spacy.tokens import Doc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_original = pd.read_csv('../data/user_original.csv')\n",
    "user_rt = pd.read_csv('../data/user_rt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-800-WOKE-AF</td>\n",
       "      <td>gloed_up</td>\n",
       "      <td>Real talk Martin real talk  this is true  Some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 GOP</td>\n",
       "      <td>10_gop</td>\n",
       "      <td>While Hurricane  bears down on Florida some pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amy Green</td>\n",
       "      <td>AmandaVGreen</td>\n",
       "      <td>And you came here so happily  The News Trends ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andy Sparks</td>\n",
       "      <td>AndyHashtagger</td>\n",
       "      <td>cakikeith what bastards she looks the bestdogn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atlanta Online</td>\n",
       "      <td>Atlanta_Online</td>\n",
       "      <td>Boy 14 hit while changing tire off I-75 in Bar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_display_name user_screen_name  \\\n",
       "0     1-800-WOKE-AF         gloed_up   \n",
       "1            10 GOP           10_gop   \n",
       "2         Amy Green     AmandaVGreen   \n",
       "3       Andy Sparks   AndyHashtagger   \n",
       "4    Atlanta Online   Atlanta_Online   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  Real talk Martin real talk  this is true  Some...  \n",
       "1  While Hurricane  bears down on Florida some pe...  \n",
       "2  And you came here so happily  The News Trends ...  \n",
       "3  cakikeith what bastards she looks the bestdogn...  \n",
       "4  Boy 14 hit while changing tire off I-75 in Bar...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_original = user_original[user_original.tweet_text != np.nan]\n",
    "user_rt = user_rt[user_rt.tweet_text != np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_vect = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "ngram_vect = TfidfVectorizer(ngram_range=(2,3), stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('police', 45863),\n",
       " ('man', 45337),\n",
       " ('new', 42104),\n",
       " ('trump', 36985),\n",
       " ('says', 24535),\n",
       " ('state', 19638),\n",
       " ('year', 18909),\n",
       " ('woman', 18385),\n",
       " ('shooting', 17978),\n",
       " ('killed', 17821),\n",
       " ('shot', 15136),\n",
       " ('city', 14836),\n",
       " ('obama', 13924),\n",
       " ('people', 13707),\n",
       " ('house', 13621),\n",
       " ('old', 13446),\n",
       " ('san', 13321),\n",
       " ('day', 13273),\n",
       " ('black', 13270),\n",
       " ('school', 13026)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_summaries = \"\".join(user_original['tweet_text'])\n",
    "original_ngrams = unigram_vect.build_analyzer()(original_summaries)\n",
    "\n",
    "Counter(original_ngrams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('police', 45863),\n",
       " ('man', 45337),\n",
       " ('new', 42104),\n",
       " ('trump', 36985),\n",
       " ('says', 24535),\n",
       " ('state', 19638),\n",
       " ('year', 18909),\n",
       " ('woman', 18385),\n",
       " ('shooting', 17978),\n",
       " ('killed', 17821),\n",
       " ('shot', 15136),\n",
       " ('city', 14836),\n",
       " ('obama', 13924),\n",
       " ('people', 13707),\n",
       " ('house', 13621),\n",
       " ('old', 13446),\n",
       " ('san', 13321),\n",
       " ('day', 13273),\n",
       " ('black', 13270),\n",
       " ('school', 13026),\n",
       " ('home', 12943),\n",
       " ('dead', 12794),\n",
       " ('crash', 12227),\n",
       " ('death', 11985),\n",
       " ('county', 11984),\n",
       " ('arrested', 11827),\n",
       " ('texas', 11714),\n",
       " ('game', 11713),\n",
       " ('clinton', 11542),\n",
       " ('car', 10590),\n",
       " ('court', 10559),\n",
       " ('say', 10468),\n",
       " ('white', 10424),\n",
       " ('video', 10087),\n",
       " ('win', 9918),\n",
       " ('president', 9801),\n",
       " ('dies', 9773),\n",
       " ('years', 9605),\n",
       " ('charged', 9565),\n",
       " ('suspect', 9503)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(original_ngrams).most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year old', 10250),\n",
       " ('new orleans', 7612),\n",
       " ('donald trump', 5095),\n",
       " ('new york', 4687),\n",
       " ('white house', 4138),\n",
       " ('st louis', 3661),\n",
       " ('san jose', 3484),\n",
       " ('high school', 3388),\n",
       " ('hillary clinton', 3335),\n",
       " ('man shot', 3319),\n",
       " ('san francisco', 3178),\n",
       " ('supreme court', 2902),\n",
       " ('police say', 2867),\n",
       " ('super bowl', 2789),\n",
       " ('pleads guilty', 2539),\n",
       " ('police officer', 2486),\n",
       " ('man charged', 2486),\n",
       " ('islamic state', 2288),\n",
       " ('health care', 2241),\n",
       " ('man arrested', 2204)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_summaries = \"\".join(user_original['tweet_text'])\n",
    "original_ngrams = ngram_vect.build_analyzer()(original_summaries)\n",
    "\n",
    "Counter(original_ngrams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year old', 10250),\n",
       " ('new orleans', 7612),\n",
       " ('donald trump', 5095),\n",
       " ('new york', 4687),\n",
       " ('white house', 4138),\n",
       " ('st louis', 3661),\n",
       " ('san jose', 3484),\n",
       " ('high school', 3388),\n",
       " ('hillary clinton', 3335),\n",
       " ('man shot', 3319),\n",
       " ('san francisco', 3178),\n",
       " ('supreme court', 2902),\n",
       " ('police say', 2867),\n",
       " ('super bowl', 2789),\n",
       " ('pleads guilty', 2539),\n",
       " ('police officer', 2486),\n",
       " ('man charged', 2486),\n",
       " ('islamic state', 2288),\n",
       " ('health care', 2241),\n",
       " ('man arrested', 2204),\n",
       " ('san diego', 2099),\n",
       " ('man accused', 2071),\n",
       " ('man killed', 1963),\n",
       " ('bay area', 1891),\n",
       " ('hit run', 1882),\n",
       " ('fort worth', 1824),\n",
       " ('fatally shot', 1775),\n",
       " ('san antonio', 1724),\n",
       " ('police blotter', 1700),\n",
       " ('los angeles', 1585),\n",
       " ('orleans saints', 1554),\n",
       " ('new orleans saints', 1491),\n",
       " ('city council', 1414),\n",
       " ('police investigating', 1410),\n",
       " ('white sox', 1374),\n",
       " ('fatal shooting', 1367),\n",
       " ('bernie sanders', 1354),\n",
       " ('north korea', 1338),\n",
       " ('old girl', 1312),\n",
       " ('year old girl', 1227)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(original_ngrams).most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 5224),\n",
       " ('im', 5084),\n",
       " ('gloed_up', 5016),\n",
       " ('like', 4735),\n",
       " ('just', 4668),\n",
       " ('dont', 4622),\n",
       " ('giselleevns', 4092),\n",
       " ('danageezus', 4011),\n",
       " ('black', 3438),\n",
       " ('amp', 3342),\n",
       " ('trump', 3165),\n",
       " ('make', 2704),\n",
       " ('trayneshacole', 2461),\n",
       " ('chrixmorgan', 2372),\n",
       " ('time', 2355),\n",
       " ('know', 2340),\n",
       " ('white', 2290),\n",
       " ('day', 2120),\n",
       " ('love', 2110),\n",
       " ('bleepthepolice', 2086)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_summaries = \"\".join(user_rt['tweet_text'])\n",
    "rt_ngrams = unigram_vect.build_analyzer()(rt_summaries)\n",
    "\n",
    "Counter(rt_ngrams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 5224),\n",
       " ('im', 5084),\n",
       " ('gloed_up', 5016),\n",
       " ('like', 4735),\n",
       " ('just', 4668),\n",
       " ('dont', 4622),\n",
       " ('giselleevns', 4092),\n",
       " ('danageezus', 4011),\n",
       " ('black', 3438),\n",
       " ('amp', 3342),\n",
       " ('trump', 3165),\n",
       " ('make', 2704),\n",
       " ('trayneshacole', 2461),\n",
       " ('chrixmorgan', 2372),\n",
       " ('time', 2355),\n",
       " ('know', 2340),\n",
       " ('white', 2290),\n",
       " ('day', 2120),\n",
       " ('love', 2110),\n",
       " ('bleepthepolice', 2086),\n",
       " ('andyhashtagger', 2061),\n",
       " ('https', 2009),\n",
       " ('new', 1944),\n",
       " ('want', 1918),\n",
       " ('think', 1895),\n",
       " ('really', 1835),\n",
       " ('good', 1826),\n",
       " ('man', 1809),\n",
       " ('id', 1680),\n",
       " ('say', 1662),\n",
       " ('worldofhashtags', 1618),\n",
       " ('best', 1610),\n",
       " ('youre', 1592),\n",
       " ('got', 1569),\n",
       " ('need', 1567),\n",
       " ('police', 1506),\n",
       " ('right', 1497),\n",
       " ('going', 1445),\n",
       " ('life', 1419),\n",
       " ('work', 1419)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(rt_ngrams).most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donald trump', 503),\n",
       " ('year old', 393),\n",
       " ('white people', 385),\n",
       " ('black people', 376),\n",
       " ('white house', 369),\n",
       " ('hashtag game', 357),\n",
       " ('dont know', 298),\n",
       " ('look like', 283),\n",
       " ('hillary clinton', 281),\n",
       " ('dont want', 274),\n",
       " ('hashtag games', 246),\n",
       " ('dont like', 237),\n",
       " ('looks like', 235),\n",
       " ('black women', 218),\n",
       " ('im going', 206),\n",
       " ('black man', 202),\n",
       " ('lives matter', 200),\n",
       " ('high school', 196),\n",
       " ('make sure', 175),\n",
       " ('im gonna', 172)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_summaries = \"\".join(user_rt['tweet_text'])\n",
    "rt_ngrams = ngram_vect.build_analyzer()(rt_summaries)\n",
    "\n",
    "Counter(rt_ngrams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donald trump', 503),\n",
       " ('year old', 393),\n",
       " ('white people', 385),\n",
       " ('black people', 376),\n",
       " ('white house', 369),\n",
       " ('hashtag game', 357),\n",
       " ('dont know', 298),\n",
       " ('look like', 283),\n",
       " ('hillary clinton', 281),\n",
       " ('dont want', 274),\n",
       " ('hashtag games', 246),\n",
       " ('dont like', 237),\n",
       " ('looks like', 235),\n",
       " ('black women', 218),\n",
       " ('im going', 206),\n",
       " ('black man', 202),\n",
       " ('lives matter', 200),\n",
       " ('high school', 196),\n",
       " ('make sure', 175),\n",
       " ('im gonna', 172),\n",
       " ('people dont', 149),\n",
       " ('united states', 145),\n",
       " ('social media', 142),\n",
       " ('black lives', 140),\n",
       " ('make america', 140),\n",
       " ('new york', 140),\n",
       " ('worldofhashtags giselleevns', 138),\n",
       " ('worldofhashtags game', 136),\n",
       " ('black woman', 133),\n",
       " ('game hosted', 133),\n",
       " ('dont think', 132),\n",
       " ('gloed_up black', 129),\n",
       " ('dont need', 129),\n",
       " ('____because hate', 129),\n",
       " ('im just', 126),\n",
       " ('gloed_up white', 124),\n",
       " ('years ago', 122),\n",
       " ('https gloed_up', 120),\n",
       " ('play hashtag', 116),\n",
       " ('black lives matter', 116)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(rt_ngrams).most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use nlp.pipe to efficiently process many docs\n",
    "original_docs = list(nlp.pipe(user_original_docs.tweet_text))\n",
    "retweet_docs = list(nlp.pipe(user_rt_docs.tweet_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('some text')\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part-of-speech tags -- token.pos_\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print('{:<12}{:<10}{:<10}'.format(token_text, token_pos, token_dep))\n",
    "#syntactic dependencies -- token.dep_\n",
    "#Named entites -- doc.ents\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # print the entity text and label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for matchid, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash table storage, lexemes\n",
    "coffee_hash = nlp.vocab.strings['coffee']\n",
    "coffee_string = nlp.vocab.strings[coffee_hash]\n",
    "lexeme = nlp.vocab['coffee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "Text-->tokenizer->tagger->parser->ner....-->Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_component(doc):\n",
    "    # do something\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipeline(custom_component, first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribute extensions\n",
    "#property extensions\n",
    "#method extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use nlp.pipe to efficiently process many docs\n",
    "docs = list(nlp.pipe(my_series_of_tweet_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and updating a model\n",
    "Initialize --> Predict --> Compare --> Calculate --> Update\n",
    "* Training data: Examples and their annotations\n",
    "* Text: The input text the model should predict a label for\n",
    "* Label: The label the model should predict.\n",
    "* Gradient: How to change the weights.\n",
    "Problems:\n",
    "* Models can forget  A. Mix in previously correct predictions\n",
    "* Models can't learn everything  A. Plan label scheme carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save your model\n",
    "nlp.to_disk(path_to_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
